---
title: "Bayesian Spatial Regression"
author: "Katie Jolly"
date: "4/18/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE, fig.align = "center")
```

This project is about vaccine exemption rates in California kindergartens. 

<br>
<br>

With the rise of the anti-vax movement, we are interested in what demographic factors might be connected or at higher risk. Previous research has shows that white, wealtier communities as well as certain immigrant communities are the most at-risk. We also acknowledge the spatial aspect of this data, making a spatial model more suitable.

My school level immunization data comes from the California Department of Health and is aggregated over the 2012-3013, 2013-2014, and 2014-2015 school years to smooth out some of the more unstable rates. My demographic data is Census data collected at the tract level. I use this data because it is the most reliable and standard. In order to connect these two datasets, I will do a spatial join to figure out which schools are in which census tracts.

<br>
<br>

## Data and packages

```{r}
library(rjags)
library(tidyverse)
library(sf)
library(extrafont)

load("~/portfolio/static/data/04_spatial_joins_zcta.RData")

demographic_and_pbe_data_clean <- demographic_and_pbe_data_zcta %>%
  select(-c(57:61, 63)) %>%
  select(-58) %>%
  st_transform(26911) %>%
  mutate_at(vars(c(2, 4:28)), funs(as.numeric)) %>%
  mutate(percent_white = ifelse(is.nan(percent_white), NA, percent_white),
         weighted_mean_pbe_rate_zcta = ifelse(is.nan(weighted_mean_pbe_rate_zcta), NA, weighted_mean_pbe_rate_zcta),
         log_weighted_mean_pbe_rate_zcta = log(weighted_mean_pbe_rate_zcta + 0.001))

theme_katie <- theme(text = element_text(family = "Franklin Gothic Book", color = "#041A26"))
```

**School level data on vaccination rates**

| Variable name | Description                                                                |
|---------------|----------------------------------------------------------------------------|
| street        | Street address of school                                                   |
| city          | City of school                                                             |
| zip           | 9-digit zip code of school                                                 |
| county_1      | County of school                                                           |
| public_priv   | Type of school (public or private)                                         |
| school_name   | Name of school                                                             |
| lat_dec       | Latitude                                                                   |
| lon_dec       | Longitude                                                                  |
| enroll_tot    | Total enrollment over 2012-2013,  2013-2014, and 2014-2015                 |
| pbe_tot       | Total personal belief exemptions  over 2012-2013, 2013-2014, and 2014-2015 |
| pbe_rate      | Total PBEs divided by total enrollment                                     |

<br> 
<br>

**Census zcta level demographic data**

| Variable name                  | Description                                                                                                |
|--------------------------------|------------------------------------------------------------------------------------------------------------|
| geoid                          | Unique identifier                                                                                          |
| estimate_total_pop             | Estimated total population in 2015                                                                         |
| name                           | Name of census zcta                                                                                       |
| moe_total_pop                  | Margin of error on total population estimate in 2015                                                       |
| estimate_total_bachelor_degree | Estimate of the total adult population with a bachelor's degree as the highest form of education in 2015   |
| estimate_hs_diploma            | Estimate of the total adult population with a high school diploma as the highest form of education in 2015 |
| estimate_total_foreign_born    | Estimate of the total population that was not born in the U.S.                                             |
| estimate_hh_med_income         | Estimate of the household median income in 2015                                                            |
| estimate_total_pop_hisp        | Estimate of the total Hispanic population in 2015                                                          |
| estimate_median_age_total      | Estimate of the median age in 2015                                                                         |
| estimate_total_white_alone     | Estimate of the population that identifies only as white in 2015                                           |

<br>
<br>

## Visualizations

<br>
<br>

```{r echo = FALSE}
outline <- tigris::states() %>%
  st_as_sf() %>%
  filter(NAME == "California") %>%
  st_transform(26911)
```

```{r}

ggplot() + 
  geom_sf(data = outline, fill = "#F4ECD6", color = "#EDD38B") + 
  geom_sf(data = demographic_and_pbe_data_zcta, aes(fill = weighted_mean_pbe_rate_zcta), color = "#D1D1D1") +
  scale_fill_gradient(low = "#BCD4DE", high = "#310A31", name = "Weighted mean PBE rate", na.value = "#F4ECD6") + theme_minimal() + theme(text = element_text(family = "Franklin Gothic Book"), panel.grid.major = element_line("transparent")) + labs(title = "PBE rates across California zip codes") +
    theme(legend.direction = "horizontal", legend.position = "bottom",
          axis.text = element_blank())
```

<br>
<br>

```{r}
ggplot(demographic_and_pbe_data_clean, aes(x = schools)) +
  geom_histogram(aes(y = ..density..), binwidth = 1, fill = "#F1E8B8", color = "white") +
  geom_density(color = "#D05353" ) +
  theme_minimal() +
  theme(text = element_text(family = "Franklin Gothic Book")) +
  labs(title = "Most zip codes have only a few schools, and the most common number is one", x= "Number of schools", y = "Density") +
  scale_x_continuous(breaks = c(1, 5, 10, 15))
```

<br>
<br>

```{r}
ggplot(demographic_and_pbe_data_clean, aes(x = percent_white, y = weighted_mean_pbe_rate_zcta)) +
  geom_point(color = "#E58F65") +
  geom_smooth(color = "#D05353") +
  theme_minimal() + 
  theme(text = element_text(family = "Franklin Gothic Book")) +
  labs(title = "In general higher white populations are more likely to have \nmore personal belief exemptions")
```

<br>
<br>


## Modeling

<br>
<br>

I start by modeling the relationship between the percent of a zip code's population that is white according to the Census and the weighted mean personal belief exemption in a zip code. 

$$\text{weighted mean pbe rate} = \beta_0 + \beta_1 * \text{percent white}$$

```{r, fig.width = 12, fig.height=12}
library(rjags)

clean_data <- demographic_and_pbe_data_clean %>%
  st_set_geometry(NULL) %>%
  select(weighted_mean_pbe_rate_zcta, percent_white) %>%
  tidyr::drop_na()


# Define the model
pbe_model <- "model{
    #Data
    for(i in 1:length(y)) {
        y[i] ~ dnorm(mu[i], tau)
        mu[i] <- beta0 + beta1*x[i]         
    }

    #Priors
    beta0 ~ dnorm(m0, t0)
    beta1 ~ dnorm(m1, t1)
    tau   ~ dgamma(s, r)
}"
    
    
# Compile the model
pbe_jags <- jags.model(textConnection(pbe_model), 
    data = list(y = clean_data$weighted_mean_pbe_rate_zcta, x = clean_data$percent_white, m0 = 0, t0 = 1/(10^2), m1 = 0.1, t1 = 1/(10^2), s = 10, r = 30000000),
    inits=list(.RNG.name="base::Wichmann-Hill", .RNG.seed=454))

    

# Simulate the model
pbe_sim <- coda.samples(pbe_jags,
    variable.names=c("beta0","beta1","tau"), 
    n.iter=10000)


# Quick plot
plot(pbe_sim)
```

<br>
<br>

```{r}
pbe_chains <- data.frame(iteration = 1:10000, pbe_sim[[1]])

cred_interval <- pbe_chains %>%
  summarise(min = quantile(beta1, 0.025), max = quantile(beta1, 0.975))

ggplot(pbe_chains, aes(x = beta1)) +
  geom_histogram(fill = "#E58F65", color = "white") +
  theme_minimal() +
  geom_vline(xintercept = cred_interval$min[1]) +
  geom_vline(xintercept = cred_interval$max[1]) +
  theme_katie +
  labs()
```

<br>
<br>

Based on this credible interval we cannot say that there is a detectable linear relationship between percent white and pbe rate. 

Next I will model the relationship between both percent white & household median income and pbe rate. 

$$\text{weighted mean pbe rate} = \beta_0 + \beta_1 * \text{percent white} + \beta_2 * \text{household median income}$$

<br>
<br>

```{r, fig.width = 12, fig.height=12}

clean_data <- demographic_and_pbe_data_clean %>%
  st_set_geometry(NULL) %>%
  select(weighted_mean_pbe_rate_zcta, percent_white, estimate_hh_med_income) %>%
  tidyr::drop_na()


# Define the model
pbe_model <- "model{
    #Data
    for(i in 1:length(y)) {
        y[i] ~ dnorm(mu[i], tau)
        mu[i] <- beta0 + beta1*x[i] + beta2*z[i]        
    }

    #Priors
    beta0 ~ dnorm(m0, t0)
    beta1 ~ dnorm(m1, t1)
    beta2 ~ dnorm(m1, t1)
    tau   ~ dgamma(s, r)
}"
    
    
# Compile the model
pbe_jags <- jags.model(textConnection(pbe_model), 
    data = list(y = clean_data$weighted_mean_pbe_rate_zcta, x = clean_data$percent_white, z = clean_data$estimate_hh_med_income, m0 = 0, t0 = 1, m1 = 0.1, t1 = 1, s = 10, r = 30000000),
    inits=list(.RNG.name="base::Wichmann-Hill", .RNG.seed=454))

    

# Simulate the model
pbe_sim <- coda.samples(pbe_jags,
    variable.names=c("beta0","beta1", "beta2", "tau"), 
    n.iter=10000)


# Quick plot
plot(pbe_sim)
```


<br>
<br>

Based on the trace plots from this model, neither the percent white or household median income have a significant linear relationship with pbe rate.

## Subsetting the data

After I made these initial models, I decided I wanted to subset the data to only a few metro areas: Los Angeles, San Diego, and San Francisco.


```{r echo = FALSE}
counties <- tigris::counties(state = "CA", year = 2015)

counties <- st_as_sf(counties)

counties_filter <- c("Orange", "Los Angeles", "San Diego", "San Francisco", "Marin", "Alameda", "Contra Costa", "San Mateo", "Santa Clara", "Sonoma", "Solano", "Napa")

counties_of_interest <- counties %>%
  filter(NAME %in% counties_filter) %>%
  st_transform(26911)

demo_pbe_data_small <- demographic_and_pbe_data_clean %>%
  st_join(counties_of_interest) %>%
  filter(!is.na(COUNTYFP))
```


I was then interested in whether or not there is actually clustering in the weighted mean pbe rates across these areas. 



```{r}
# morans i: global clustering
library(spdep)
library(ape)
st_rook = function(a, b = a) st_relate(a, b, pattern = "F***1****")

pbe_data <- demo_pbe_data_small %>%
  mutate(weighted_mean_pbe_rate_zcta_clean = replace_na(weighted_mean_pbe_rate_zcta, 0)) %>%
  mutate(NB_ROOK = st_rook(.)) 

for (i in 1:nrow(pbe_data)){
  pbe_data$nb_length[i] <- length(pbe_data$NB_ROOK[[i]])
}

pbe_data <- pbe_data %>%
  select(-NB_ROOK) %>%
  filter(nb_length > 0)

ggplot(pbe_data) + geom_sf(fill = "#51A3A3", color = "#ADD3D3") + theme_minimal() +
  theme(panel.grid.major = element_line("transparent")) +
  theme(text = element_text(family = "Segoe UI Light"),
        axis.text = element_blank()) +
  labs(title = "Zip codes with at least one neighbor")

pbe_sp <- as(pbe_data, "Spatial")
pbe_nb <- poly2nb(pbe_sp)
pbe_w <- nb2listw(pbe_nb, style = "B")

moran.mc(pbe_sp$weighted_mean_pbe_rate_zcta_clean, pbe_w, nsim = 9999) # mc simulations
```

I did a hypothesis test of whether of not there is positive spatial autocorrelation (clustering) in these metropolitan areas. 

$$H_0: I=0, \text{ completely spatially random}\\
H_a: I > 0, \text{ spatially clustered} $$

To test this hypothesis I did a Monte Carlo test. This test randomly assigns values to the polygons in my data and calculates Moran's I for each of these iterations. It then finds where our observed statistic falls in this distribution of possible statistics. My simulation included 10,000 iterations and found that the clustering in my observed data was more extreme than any of the random distributions, meaning we can reject the null hypothesis that there the data are completely spatially random. This means that spatial models are worthwhile for doing a regression analysis. 

Before doing that, though, I am also interested in local hotspots and outliers in the data. To calculate this I will use local Moran's I. This statistic essentially looks for groups of observations that are far above or below the expected value. 

```{r}


# create  Queens contiguity matrix
spatmatrix <- poly2nb(pbe_sp)

# create a neighbours list with spatial weights
listw <- nb2listw(spatmatrix)

# calculate the local moran of the distribution of white population
lmoran <- localmoran(pbe_sp$weighted_mean_pbe_rate_zcta_clean, listw)
summary(lmoran)

# padronize the variable and save it to a new column
pbe_sp$s_pbe <- scale(pbe_sp$weighted_mean_pbe_rate_zcta_clean)  %>% as.vector()

# create a spatially lagged variable and save it to a new column
pbe_sp$lag_s_pbe <- lag.listw(listw, pbe_sp$s_pbe)

# summary of variables, to inform the analysis
summary(pbe_sp$s_pbe)
summary(pbe_sp$lag_s_pbe)

# create a new variable identifying the moran plot quadrant for each observation, dismissing the non-significant ones
pbe_sp$quad_sig <- NA

# high-high quadrant
pbe_sp[(pbe_sp$s_pbe >= 0 & 
                 pbe_sp$lag_s_pbe >= 0) & 
                (lmoran[, 5] <= 0.05), "quad_sig"] <- "high-high"
# low-low quadrant
pbe_sp[(pbe_sp$s_pbe <= 0 & 
                 pbe_sp$lag_s_pbe <= 0) & 
                (lmoran[, 5] <= 0.05), "quad_sig"] <- "low-low"
# high-low quadrant
pbe_sp[(pbe_sp$s_pbe >= 0 & 
                 pbe_sp$lag_s_pbe <= 0) & 
                (lmoran[, 5] <= 0.05), "quad_sig"] <- "high-low"
# low-high quadrant
pbe_sp@data[(pbe_sp$s_pbe <= 0 
               & pbe_sp$lag_s_pbe >= 0) & 
                (lmoran[, 5] <= 0.05), "quad_sig"] <- "low-high"
# non-significant observations
pbe_sp@data[(lmoran[, 5] > 0.05), "quad_sig"] <- "not signif."  

pbe_sp$quad_sig <- as.factor(pbe_sp$quad_sig)
pbe_sp@data$id <- rownames(pbe_sp@data)

# plotting the map
df <- fortify(pbe_sp, region="id")
df <- left_join(df, pbe_sp@data)
df %>% 
  ggplot(aes(long, lat, group = group, fill = quad_sig)) + 
  geom_polygon(color = "white", size = .05)  + coord_equal() + 
  theme_void() +
  theme(text = element_text(family = "Segoe UI Light")) + 
  scale_fill_manual(values = c("#DD7373", "#D1d1d1"), name = "Cluster type") +
  labs(title = "Local spatial autocorrelation in PBE rates")
```

The areas highlighted in red are hotspots of high PBE rates. 

# CarBAYES model

```{r eval = FALSE}
# haven't run this yet but I will later. I checked that it will start running, though
library(CARBayes)
pbe_data <- pbe_data %>%
  mutate(percent_white = replace_na(percent_white, 0))

pbe_sp <- as(pbe_data %>% dplyr::select(c(percent_white, weighted_mean_pbe_rate_zcta_clean)), "Spatial")
pbe_nb <- poly2nb(pbe_sp)
W <- nb2mat(pbe_nb, style="B", zero.policy=TRUE)

perWhite <- pbe_sp$percent_white
Z.perWhite <- as.matrix(dist(perWhite, diag=TRUE, upper=TRUE))
formula <- weighted_mean_pbe_rate_zcta_clean ~ 1
model.dissimilarity <- S.CARdissimilarity(formula=formula, data=pbe_sp, family="gaussian", W=W, Z=list(Z.perWhite=Z.perWhite), W.binary=TRUE, burnin=10000, n.sample=30000, thin=20)
```

